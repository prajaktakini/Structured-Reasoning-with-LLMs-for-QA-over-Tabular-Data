{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jPisO9pontYd"
   },
   "source": [
    "# Pre-Requisites: Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I3L5Rc71nLqy"
   },
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R9ubCf3_xjbz"
   },
   "outputs": [],
   "source": [
    "USE_GROQ = True  # Set to False to use OpenAI\n",
    "REQUEST_DELAY = 0.5\n",
    "\n",
    "GROQ_MODEL = \"llama3-70b-8192\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "22or7Dm9nOSr"
   },
   "source": [
    "## Install Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6021,
     "status": "ok",
     "timestamp": 1746644198839,
     "user": {
      "displayName": "Prajakta Kini",
      "userId": "16853765155046300123"
     },
     "user_tz": 360
    },
    "id": "MVWYw6hPrysR",
    "outputId": "fff633e6-0712-4eb7-a6da-5fef33a04a67"
   },
   "outputs": [],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9380,
     "status": "ok",
     "timestamp": 1746644208219,
     "user": {
      "displayName": "Prajakta Kini",
      "userId": "16853765155046300123"
     },
     "user_tz": 360
    },
    "id": "G6OkV0nOxAnG",
    "outputId": "2d5b4abe-f0ef-4bd2-c7e5-730c3590a069"
   },
   "outputs": [],
   "source": [
    "!pip install openai\n",
    "!pip install groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6668,
     "status": "ok",
     "timestamp": 1746644214888,
     "user": {
      "displayName": "Prajakta Kini",
      "userId": "16853765155046300123"
     },
     "user_tz": 360
    },
    "id": "DHP5F1HQtNEF",
    "outputId": "64407816-71ee-4454-f9e1-3f20b2773ec3"
   },
   "outputs": [],
   "source": [
    "!pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GS881QqWnSaK"
   },
   "source": [
    "## All Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fep4o9oHsEdf"
   },
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "from groq import Groq\n",
    "import openai\n",
    "import json\n",
    "import ast\n",
    "import warnings\n",
    "import time\n",
    "\n",
    "# Data handling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch\n",
    "from itertools import cycle\n",
    "import faiss\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "from huggingface_hub import login\n",
    "login(\"TOKEN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AIYZO2Txnopl"
   },
   "source": [
    "## Load Groq API Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0THvDg6Jvy-y"
   },
   "outputs": [],
   "source": [
    "# List of your GROQ API keys\n",
    "GROQ_API_KEYS = [\n",
    "     \"API_KEY\",\n",
    "\n",
    "]\n",
    "\n",
    "# Create a cycling iterator over the API keys\n",
    "groq_clients = [Groq(api_key=key) for key in GROQ_API_KEYS]\n",
    "groq_client_cycle = cycle(groq_clients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wNK_9ikTofU9"
   },
   "source": [
    "## Load Entire QA Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "referenced_widgets": [
      "a69d5670b6044933a9db4631e620b616",
      "fc3cab9669ec43f68738cde38c3fe371",
      "f9ed95f1674748fa8c25d241d246afee",
      "f076622195604fdaae964eb3358d20d5",
      "0a936db83b9c4f1ca4a9c707421e3e13",
      "33e039fa6189410fa5cc39f8c2d29e08",
      "849c666e5ccd4d8c907e905806ea46e7",
      "1cbb686141b842df83b1cec0475ae901",
      "964fc883519e4b2f96464a677fba1ba7",
      "7468009e25ea4b119a4cc52293d58187",
      "5205fe29aa824c8686b28f2ec9efe391",
      "7e2bab8db6d346f98fa3267bdbc9e59c",
      "e36d9ce8ce454e65b14302d121d339b0",
      "6376ec3407fb46f4b998e4fa8bbe03bb",
      "7fa8edcdcb5e4eaea262f492f0840fd3",
      "b8b9d7011a854c9ea6fe44730d5db597",
      "4bb84fef40804ec8b96e20b5213fa37b",
      "fcb7f8416ad3492da1c3cb6b258ceb3c",
      "46a45a3a813c4dad9ba1aa890a997146",
      "2b3557747e174778b9bd3702a20e661c",
      "eebc0baa16734ae8917f268978c80800",
      "32bcba98349941e08087ee9836e404c7"
     ]
    },
    "executionInfo": {
     "elapsed": 1215,
     "status": "ok",
     "timestamp": 1746644217806,
     "user": {
      "displayName": "Prajakta Kini",
      "userId": "16853765155046300123"
     },
     "user_tz": 360
    },
    "id": "_J2_Zfn2sczf",
    "outputId": "a5388646-16bc-49e9-ae7d-0c6d028b068e"
   },
   "outputs": [],
   "source": [
    "dataset_name = \"cardiffnlp/databench\"\n",
    "# semeval_train = load_dataset(dataset_name, name=\"semeval\", split=\"train\")\n",
    "# semeval_dev = load_dataset(dataset_name, name=\"semeval\", split=\"dev\")\n",
    "\n",
    "semeval_train = load_dataset(dataset_name, name=\"qa\", split=\"train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I_15whgiojFt"
   },
   "source": [
    "## Updates 'column_used' function from QA dataset\n",
    "\n",
    "1.  Converts value to String format by adding quotes\n",
    "2.  Escapes inner quotes\n",
    "3. If column name has <gx:[^>]+>: regex pattern, strips it\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FkrvAuY5PAzz"
   },
   "outputs": [],
   "source": [
    "def safe_parse_list(raw):\n",
    "    import ast\n",
    "    import re\n",
    "\n",
    "    if isinstance(raw, list):\n",
    "        return raw\n",
    "\n",
    "    if isinstance(raw, str):\n",
    "        try:\n",
    "            parsed = ast.literal_eval(raw)\n",
    "            if isinstance(parsed, list):\n",
    "                return parsed\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            # Manually fix unquoted or single-quoted elements\n",
    "            if raw.startswith(\"[\") and raw.endswith(\"]\"):\n",
    "                inner = raw[1:-1].strip()\n",
    "                if inner and not inner.startswith((\"'\", '\"')):\n",
    "                    # Case: [Weight, Height] -> Update to Str format by adding quotes around\n",
    "                    parts = [p.strip() for p in inner.split(\",\")]\n",
    "                    quoted = [f'\"{p}\"' for p in parts if p]\n",
    "                    fixed = \"[\" + \", \".join(quoted) + \"]\"\n",
    "                else:\n",
    "                    # Case: [\"What's your name?\"] # Escape inner quotes\n",
    "                    inner = raw[1:-1]\n",
    "                    fixed_inner = re.sub(r'([\"\\'])', r'\\\\\\1', inner)\n",
    "                    fixed = f'[\"{fixed_inner}\"]'\n",
    "                parsed = ast.literal_eval(fixed)\n",
    "                if isinstance(parsed, list):\n",
    "                    return parsed\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to parse used_cols string: {raw} | Reason: {e}\")\n",
    "\n",
    "    return raw # should never happen\n",
    "\n",
    "def clean_columns_used(col_list):\n",
    "    parsed = safe_parse_list(col_list)\n",
    "\n",
    "    if not isinstance(parsed, list):\n",
    "        return [str(parsed)] if parsed is not None else []\n",
    "\n",
    "    cleaned = []\n",
    "    for col in parsed:\n",
    "        col = str(col)\n",
    "        col = re.sub(r\"<gx:[^>]+>\", \"\", col).strip()\n",
    "        cleaned.append(col)\n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9Swi6js7VpbS"
   },
   "outputs": [],
   "source": [
    "# Update column names using Map as HuggingFace dataframes are immutable\n",
    "def update_columns_used(example):\n",
    "    example[\"columns_used\"] = clean_columns_used(example.get(\"columns_used\"))\n",
    "    return example\n",
    "\n",
    "# Apply the function to update each sample in the datasets\n",
    "semeval_train = semeval_train.map(update_columns_used)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xdKag54cpDtB"
   },
   "source": [
    "## Unique Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1746644351868,
     "user": {
      "displayName": "Prajakta Kini",
      "userId": "16853765155046300123"
     },
     "user_tz": 360
    },
    "id": "ZtpjtaTCciji",
    "outputId": "9694c4cb-02b4-4be7-8c8a-626da6c3e191"
   },
   "outputs": [],
   "source": [
    "# unique_train_datasets = list(set(semeval_train.unique(\"dataset\")))\n",
    "unique_train_datasets = [\n",
    "    \"001_Forbes\", \"002_Titanic\", \"004_Taxi\", \"005_NYC\",\n",
    "    \"006_London\", \"007_Fifa\", \"008_Tornados\", \"009_Central\", \"010_ECommerce\",\n",
    "    \"011_SF\", \"012_Heart\", \"013_Roller\", \"015_Food\",\n",
    "    \"016_Holiday\", \"017_Hacker\", \"018_Staff\", \"019_Aircraft\",\n",
    "    \"021_Telco\", \"022_Airbnbs\", \"023_Climate\", \"024_Salary\", \"025_Data\",\n",
    "    \"026_Predicting\", \"027_Supermarket\", \"028_Predict\", \"029_NYTimes\", \"030_Professionals\",\n",
    "    \"031_Trustpilot\", \"032_Delicatessen\", \"033_Employee\", \"034_World\",\n",
    "    \"036_US\", \"037_Ted\", \"038_Stroke\", \"039_Happy\", \"040_Speed\",\n",
    "    \"041_Airline\", \"042_Predict\", \"043_Predict\", \"044_IMDb\", \"045_Predict\",\n",
    "    \"046_120\", \"047_Bank\", \"048_Data\",  \"050_ING\",\n",
    "    \"051_Pokemon\", \"052_Professional\", \"053_Patents\", \"055_German\",\n",
    "    \"056_Emoji\", \"057_Spain\", \"058_US\", \"059_Second\", \"060_Bakery\",\n",
    "    \"061_Disneyland\", \"062_Trump\", \"063_Influencers\", \"064_Clustering\", \"065_RFM\"\n",
    "]\n",
    "\n",
    "\n",
    "print(f\"Unique Train Datasets: {unique_train_datasets}\")\n",
    "\n",
    "# unique_dev_datasets = list(set(semeval_dev.unique(\"dataset\")))\n",
    "# print(f\"Unique Dev Datasets: {unique_dev_datasets}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JxHXuxl8pOQv"
   },
   "source": [
    "## Create Dictionary of {Dataset_Name: Dataset}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OiTUugTHv6A_"
   },
   "outputs": [],
   "source": [
    "train_dataset_map = {}\n",
    "# unique_train_datasets = list(set(semeval_train.unique(\"dataset\")))\n",
    "\n",
    "for dataset in unique_train_datasets:\n",
    "    train_dataset_map[dataset] = pd.read_parquet(f\"hf://datasets/cardiffnlp/databench/data/{dataset}/sample.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1746644389163,
     "user": {
      "displayName": "Prajakta Kini",
      "userId": "16853765155046300123"
     },
     "user_tz": 360
    },
    "id": "WYDXpIGTliFF",
    "outputId": "6b27536e-91f8-4c78-a951-95f944c0a7ab"
   },
   "outputs": [],
   "source": [
    "print(len(train_dataset_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1746644389170,
     "user": {
      "displayName": "Prajakta Kini",
      "userId": "16853765155046300123"
     },
     "user_tz": 360
    },
    "id": "cGvavNpyutzw",
    "outputId": "204b3041-969c-41bf-9f8e-fc8dd3011e2a"
   },
   "outputs": [],
   "source": [
    "print(unique_train_datasets)\n",
    "print(len(unique_train_datasets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V-pRaEo8pVKf"
   },
   "source": [
    "## Clean column names from dataset dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RzV1M4G4XrSd"
   },
   "outputs": [],
   "source": [
    "# Function to clean column names by removing <gx:...> part\n",
    "def clean_column_name(col_name):\n",
    "    # Use regex to remove the <gx:...> part\n",
    "    cleaned = re.sub(r'<gx:[^>]+>', '', col_name)\n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dd1Mpr7hXpQA"
   },
   "outputs": [],
   "source": [
    "for ds in train_dataset_map.keys():\n",
    "    df = train_dataset_map[ds]\n",
    "\n",
    "    column_mapping = {col: clean_column_name(col) for col in df.columns}\n",
    "    df = df.rename(columns=column_mapping)\n",
    "\n",
    "    # Store the updated dataframe back in the hashmap\n",
    "    train_dataset_map[ds] = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gJoDDVKWs2So"
   },
   "source": [
    "## Ignore -> Don't RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 62,
     "status": "ok",
     "timestamp": 1746644398106,
     "user": {
      "displayName": "Prajakta Kini",
      "userId": "16853765155046300123"
     },
     "user_tz": 360
    },
    "id": "o6wVqK1FDcRj",
    "outputId": "a6814e27-ad36-48d5-c1dd-b59ee628eb71"
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import ast\n",
    "\n",
    "import ast\n",
    "import re\n",
    "\n",
    "def safe_parse_columns(raw):\n",
    "    if isinstance(raw, list):\n",
    "        return raw\n",
    "    if not isinstance(raw, str):\n",
    "        return []\n",
    "\n",
    "    try:\n",
    "        # Check if elements are unquoted and fix: [Name, Age] â†’ [\"Name\", \"Age\"]\n",
    "        if re.match(r\"\\[\\s*[A-Za-z0-9_]+(,\\s*[A-Za-z0-9_]+)*\\s*\\]\", raw):\n",
    "            raw = re.sub(r'([A-Za-z0-9_]+)', r'\"\\1\"', raw)\n",
    "        parsed = ast.literal_eval(raw)\n",
    "        if isinstance(parsed, list):\n",
    "            return parsed\n",
    "    except Exception as e:\n",
    "        print(f\" Failed to parse used_cols string: {raw} | Reason: {e}\")\n",
    "    return []\n",
    "\n",
    "\n",
    "# Step 1: Group questions by dataset\n",
    "questions_by_dataset = defaultdict(list)\n",
    "\n",
    "for sample in semeval_train:\n",
    "    dataset = sample['dataset']\n",
    "    question = sample['question']\n",
    "    used_cols = sample['columns_used']\n",
    "    questions_by_dataset[dataset].append({\n",
    "        \"question\": question,\n",
    "        \"used_cols\": used_cols\n",
    "    })\n",
    "\n",
    "# Step 2: Compare used columns with actual columns in the dataset\n",
    "for ds, entries in questions_by_dataset.items():\n",
    "    print(f\"Dataset: {ds}\")\n",
    "    if ds not in train_dataset_map:\n",
    "        print(f\"\\nâš ï¸ Dataset '{ds}' not found in train_dataset_map.\")\n",
    "        continue\n",
    "\n",
    "    actual_cols = set(train_dataset_map[ds].columns.tolist())\n",
    "\n",
    "    used_cols = set()\n",
    "    for entry in entries:\n",
    "        parsed_cols = safe_parse_columns(entry.get(\"used_cols\"))\n",
    "        used_cols.update(parsed_cols)\n",
    "\n",
    "\n",
    "    missing = used_cols - actual_cols  # predicted but not present\n",
    "    if missing:\n",
    "        print(f\"\\nðŸ“˜ Dataset: {ds}\")\n",
    "        print(f\"\\nActul Columns: {actual_cols}\")\n",
    "        print(f\"\\nUsed Columns Gold Labels: {used_cols}\")\n",
    "\n",
    "        print(f\"âš ï¸  Columns used in sample but not found in dataset: {missing}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JMIm4sUjtAGl"
   },
   "source": [
    "## Serialize a Row to Key-Value Pair format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uE_2OEP9s-wJ"
   },
   "outputs": [],
   "source": [
    "def serialize_to_kv_format(df, dropna=True):\n",
    "    kv_serialized = []\n",
    "    for _, row in df.iterrows():\n",
    "        kv_pairs = []\n",
    "        for col, val in row.items():\n",
    "            if pd.isna(val) and dropna:\n",
    "                continue\n",
    "            if isinstance(val, str):\n",
    "                val = f'\"{val}\"'\n",
    "            kv_pairs.append(f\"{col}: {val}\")\n",
    "        row_str = \"{\" + \", \".join(kv_pairs) + \"}\"\n",
    "        kv_serialized.append(row_str)\n",
    "    return kv_serialized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5mU0w8-QtFUv"
   },
   "source": [
    "## Build LLM Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JxDiN55dv8ii"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# def build_prompt(df: pd.DataFrame, question: str, explain: bool = False) -> str:\n",
    "#     kv_serialized = serialize_to_kv_format(df)\n",
    "#     response_format = (\n",
    "#         'You must answer in a single JSON with two fields:\\n'\n",
    "#         '* \"answer\": your final answer based on the records.\\n'\n",
    "#         '* \"columns_used\": list of relevant columns.'\n",
    "#     )\n",
    "#     prompt_body = f\"\"\"You are an assistant tasked with answering the questions asked of a given dataset in JSON format.\\n{response_format}\\nRequirements:\\n* Only respond with the JSON. Your answer must contain only the final value(s), not explanations or full objects.\\nIn the following key-value formatted data:\\n```kv\\n{kv_serialized}\\n```\\nUSER: {question}\\nASSISTANT:\"\"\"\n",
    "#     return f\"[INST]\\n{prompt_body}\\n[/INST]\"\n",
    "\n",
    "def build_prompt(df: pd.DataFrame, question: str) -> str:\n",
    "    kv_serialized = serialize_to_kv_format(df)\n",
    "\n",
    "    response_format = (\n",
    "        'You must answer in a single JSON with two fields:\\n'\n",
    "        '* \"answer\": your final answer based on the records.\\n'\n",
    "        '* \"columns_used\": list of relevant columns.'\n",
    "    )\n",
    "\n",
    "    prompt_body = (\n",
    "        \"You are an assistant tasked with answering questions asked of a given dataset in JSON format.\\n\"\n",
    "        f\"{response_format}\\n\"\n",
    "        \"Requirements:\\n\"\n",
    "        \"* Only respond with the JSON. Do not include explanations or full objects.\\n\"\n",
    "        \"* Your answer must use valid Python data types:\\n\"\n",
    "        \"  - Use `True` or `False` (capitalized) for boolean values.\\n\"\n",
    "        \"  - Use numbers as Python `int` or `float` (e.g., `3`, `3.14`).\\n\"\n",
    "        \"  - Use double-quoted Python strings for categorical values (e.g., \\\"USA\\\").\\n\"\n",
    "        \"  - Use Python lists for answers involving multiple values:\\n\"\n",
    "        \"    - For list[category], return a list of strings.\\n\"\n",
    "        \"    - For list[number], return a list of ints or floats.\\n\"\n",
    "        \"    - Ensure all inner values match the correct type.\\n\\n\"\n",
    "        \"In the following key-value formatted data:\\n\"\n",
    "        \"```kv\\n\"\n",
    "        f\"{kv_serialized}\\n\"\n",
    "        \"```\\n\"\n",
    "        f\"USER: {question}\\n\"\n",
    "        \"ASSISTANT:\"\n",
    "    )\n",
    "\n",
    "    return f\"[INST]\\n{prompt_body}\\n[/INST]\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LmuTUAzJtjhg"
   },
   "source": [
    "## Util functions for processing column info for dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lTgOKWovoeR0"
   },
   "outputs": [],
   "source": [
    "def try_parse_list(val):\n",
    "    \"\"\"Try to parse a stringified list, else return original\"\"\"\n",
    "    if isinstance(val, str) and val.startswith(\"[\") and val.endswith(\"]\"):\n",
    "        try:\n",
    "            parsed = ast.literal_eval(val)\n",
    "            if isinstance(parsed, list):\n",
    "                return parsed\n",
    "        except:\n",
    "            pass\n",
    "    return val\n",
    "\n",
    "def detect_url(val) -> bool:\n",
    "    if not isinstance(val, str):\n",
    "        return False\n",
    "    val = val.strip()\n",
    "    return val.startswith(\"http://\") or val.startswith(\"https://\") or val.startswith(\"www.\")\n",
    "\n",
    "def detect_number(val) -> bool:\n",
    "    try:\n",
    "        return isinstance(val, (int, float)) or float(str(val))\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def detect_boolean(val) -> bool:\n",
    "    if isinstance(val, bool): return True\n",
    "    if isinstance(val, str): return val.strip().lower() in [\"true\", \"false\"]\n",
    "    if isinstance(val, (int, float)): return val in [0, 1]\n",
    "    return False\n",
    "\n",
    "def detect_date(val) -> bool:\n",
    "    try:\n",
    "        # Suppress UserWarning about ambiguous day/month formats\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\", UserWarning)\n",
    "            parsed = pd.to_datetime(val, errors=\"raise\", dayfirst=False)\n",
    "        return isinstance(parsed, pd.Timestamp)\n",
    "    except Exception:\n",
    "        try:\n",
    "            with warnings.catch_warnings():\n",
    "                warnings.simplefilter(\"ignore\", UserWarning)\n",
    "                parsed = pd.to_datetime(val, errors=\"raise\", dayfirst=True)\n",
    "            return isinstance(parsed, pd.Timestamp)\n",
    "        except:\n",
    "            return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8lZ2GRb0t8D3"
   },
   "source": [
    "## Identify column type\n",
    "For each column in the dataset to be inserted as metadata for building FAISS indexing over column data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mOKaES_jt0rA"
   },
   "outputs": [],
   "source": [
    "def get_column_type(values, col_name=\"\", sample_size=20) -> str:\n",
    "    # Parse stringified lists\n",
    "    parsed = [try_parse_list(v) for v in values if pd.notna(v) and v not in [\"\", \"nan\", \"NaN\"]]\n",
    "    parsed = parsed[:sample_size]\n",
    "\n",
    "    if not parsed:\n",
    "        if \"category\" in col_name.lower() or \"id\" in col_name.lower():\n",
    "            return \"category\"\n",
    "        return \"empty\"\n",
    "\n",
    "    first = parsed[0]\n",
    "\n",
    "    # List-type\n",
    "    if isinstance(first, list):\n",
    "        inner_vals = [item for sublist in parsed if isinstance(sublist, list) for item in sublist]\n",
    "        if not inner_vals:\n",
    "            return \"list[empty]\"\n",
    "        if all(detect_number(v) for v in inner_vals):\n",
    "            return \"list[number]\"\n",
    "        if all(detect_url(v) for v in inner_vals):\n",
    "            return \"list[url]\"\n",
    "        if all(detect_boolean(v) for v in inner_vals):\n",
    "            return \"list[boolean]\"\n",
    "        return \"list[category]\"\n",
    "\n",
    "    # Scalar-type\n",
    "    if all(detect_boolean(v) for v in parsed): return \"boolean\"\n",
    "    if all(detect_number(v) for v in parsed): return \"number\"\n",
    "    if all(detect_url(v) for v in parsed): return \"url\"\n",
    "    if all(detect_date(v) for v in parsed): return \"date\"\n",
    "    if len(set(map(str, parsed))) < sample_size / 2: return \"category\"\n",
    "    if any(len(str(v)) > 30 for v in parsed): return \"text\"\n",
    "    return \"string\"\n",
    "\n",
    "def get_all_column_types(df: pd.DataFrame) -> dict:\n",
    "    return {\n",
    "        col: get_column_type(df[col].tolist(), col_name=col)\n",
    "        for col in df.columns\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mApdRVXGuOxR"
   },
   "source": [
    "## Initialize Embedder and FAISS indexing store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6IsKn8WlzCF7"
   },
   "outputs": [],
   "source": [
    "# Retrieval Component\n",
    "from typing import Dict, List, Tuple\n",
    "embedder = SentenceTransformer(\"BAAI/bge-small-en-v1.5\")\n",
    "\n",
    "# Store per-dataset FAISS index and metadata\n",
    "dataset_faiss_store: Dict[str, Dict] = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JOPKd1veugPa"
   },
   "source": [
    "## Build index over single dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hr_okBRIU3xv"
   },
   "outputs": [],
   "source": [
    "# Format column as descriptive string\n",
    "def format_column_for_embedding(col_name: str, values: List[str], dtype: str) -> str:\n",
    "    sample = ', '.join(map(str, values[:5]))\n",
    "    return f\"Column '{col_name}': {dtype} column with values like [{sample}].\"\n",
    "\n",
    "# Index one dataset from DataFrame\n",
    "def index_single_dataset(dataset_name: str, df: pd.DataFrame):\n",
    "    column_meta = []\n",
    "    embed_strings = []\n",
    "\n",
    "    for col in df.columns:\n",
    "        sample_values = df[col].dropna().astype(str).tolist()[:2]\n",
    "        col_type = get_column_type(df[col].tolist(), col_name=col)\n",
    "\n",
    "        embed_text = format_column_for_embedding(col, sample_values, col_type)\n",
    "\n",
    "        column_meta.append({\n",
    "            \"col_name\": col,\n",
    "            \"type\": col_type,\n",
    "            \"sample_values\": sample_values,\n",
    "            \"embed_text\": embed_text\n",
    "        })\n",
    "        embed_strings.append(embed_text)\n",
    "\n",
    "\n",
    "    print(embed_strings)\n",
    "    # Embed all columns\n",
    "    column_embeddings = embedder.encode(embed_strings, convert_to_numpy=True)\n",
    "    print(column_embeddings)\n",
    "    faiss.normalize_L2(column_embeddings)\n",
    "\n",
    "    # Create FAISS index\n",
    "    dim = column_embeddings.shape[1]\n",
    "    index = faiss.IndexFlatIP(dim)\n",
    "    index.add(column_embeddings)\n",
    "\n",
    "    dataset_faiss_store[dataset_name] = {\n",
    "        \"index\": index,\n",
    "        \"columns\": [m[\"col_name\"] for m in column_meta],\n",
    "        \"metadata\": column_meta\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "deWsFNe_hIN6"
   },
   "source": [
    "## Index all datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22060,
     "status": "ok",
     "timestamp": 1746644448867,
     "user": {
      "displayName": "Prajakta Kini",
      "userId": "16853765155046300123"
     },
     "user_tz": 360
    },
    "id": "ogpe1zKVXape",
    "outputId": "18b97ec2-a625-456d-fa86-3b7c9b2efd67"
   },
   "outputs": [],
   "source": [
    "# Index all CSV datasets in a folder\n",
    "def index_all_datasets():\n",
    "    for ds in unique_train_datasets:\n",
    "        df = train_dataset_map[ds]\n",
    "        index_single_dataset(ds, df)\n",
    "\n",
    "index_all_datasets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oP5NnTE9vL1m"
   },
   "source": [
    "## Print Indexed Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1746644448916,
     "user": {
      "displayName": "Prajakta Kini",
      "userId": "16853765155046300123"
     },
     "user_tz": 360
    },
    "id": "y-twKD8TyhRv",
    "outputId": "d117ab64-9645-4423-b481-8036cf4c2eb8"
   },
   "outputs": [],
   "source": [
    "print(\"Indexed datasets:\", list(dataset_faiss_store.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zy0u3LrbvUej"
   },
   "source": [
    "## Util Function to Retrieve Top-K columns for a question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B461dx4cXbQ2"
   },
   "outputs": [],
   "source": [
    "# Retrieve top-k most relevant columns for a question\n",
    "def retrieve_columns_for_question(dataset_name: str, question: str, k: int = 3) -> List[str]:\n",
    "    dataset = dataset_faiss_store[dataset_name]\n",
    "    index = dataset[\"index\"]\n",
    "    columns = dataset[\"columns\"]\n",
    "\n",
    "    q_emb = embedder.encode([question], convert_to_numpy=True)\n",
    "    faiss.normalize_L2(q_emb)\n",
    "\n",
    "    scores, indices = index.search(q_emb, k)\n",
    "    return [columns[i] for i in indices[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7bLN3H_0vlJY"
   },
   "source": [
    "## Ignore for now [Exploration]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 356
    },
    "executionInfo": {
     "elapsed": 5715,
     "status": "error",
     "timestamp": 1746644490537,
     "user": {
      "displayName": "Prajakta Kini",
      "userId": "16853765155046300123"
     },
     "user_tz": 360
    },
    "id": "X5vw1pyCxtLD",
    "outputId": "78c8f67b-8c48-4d7d-8a21-4ea883bce2cd"
   },
   "outputs": [],
   "source": [
    "missing_expected_cols = []\n",
    "for sample in semeval_train:\n",
    "    dataset = sample['dataset']\n",
    "    question = sample['question']\n",
    "    expected_columns = sample['columns_used']\n",
    "\n",
    "    if dataset in unique_train_datasets:\n",
    "\n",
    "      df_cols = train_dataset_map[dataset].columns.tolist()\n",
    "\n",
    "      cols = retrieve_columns_for_question(dataset, question, 4)\n",
    "\n",
    "\n",
    "\n",
    "      # Validate that all retrieved columns exist in the dataset\n",
    "      missing_cols = [col for col in cols if col not in df_cols]\n",
    "      expected_col = []\n",
    "      expected_col = [col for col in expected_col if col not in cols]\n",
    "\n",
    "      if expected_col:\n",
    "          missing_expected_cols.append(expected_col)\n",
    "      else:\n",
    "          missing_expected_cols.append([])\n",
    "\n",
    "      if missing_cols:\n",
    "          raise ValueError(\n",
    "              f\"Retrieved columns not found in dataset '{dataset}': {missing_cols}\\n\"\n",
    "              f\"Available columns: {df_cols}\"\n",
    "          )\n",
    "      #print(f\"Dataset: {dataset}, question: {question}, Columns returned: {cols}\")\n",
    "\n",
    "print(missing_expected_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e7dKQYJAvpay"
   },
   "source": [
    "## SET LLM MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YPiXRsls80un"
   },
   "outputs": [],
   "source": [
    "# GROQ_MODEL = \"llama3-70b-8192\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cMdklc-YwACi"
   },
   "outputs": [],
   "source": [
    "def generate_model_response(prompt):\n",
    "    \"\"\"\n",
    "    Generates a response using Groq (LLaMA-3) or OpenAI (GPT-3.5).\n",
    "    Falls back across multiple Groq keys if needed.\n",
    "    \"\"\"\n",
    "    if USE_GROQ:\n",
    "        for attempt in range(len(groq_clients)):\n",
    "            groq_client = next(groq_client_cycle)\n",
    "\n",
    "            try:\n",
    "                response = groq_client.chat.completions.create(\n",
    "                    model=GROQ_MODEL,\n",
    "                    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                    temperature=0.7,\n",
    "                    max_tokens=512,\n",
    "                    top_p=1.0\n",
    "                )\n",
    "                return response.choices[0].message.content\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"[Groq Attempt {attempt + 1}] Error: {e}\")\n",
    "                continue\n",
    "\n",
    "        return \"All Groq API keys exhausted or rate limited.\"\n",
    "\n",
    "    else:\n",
    "        try:\n",
    "            response = openai.ChatCompletion.create(\n",
    "                model=\"gpt-3.5-turbo\",\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                temperature=0.7,\n",
    "                max_tokens=512,\n",
    "                top_p=1.0\n",
    "            )\n",
    "            return response.choices[0].message[\"content\"]\n",
    "\n",
    "        except Exception as e:\n",
    "            return f\"OpenAI request failed: {e}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lEQJwbyyv-fR"
   },
   "source": [
    "## Util functions to Process Retrieved Model Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aW1U5HfdXutK"
   },
   "outputs": [],
   "source": [
    "def normalize_number(value):\n",
    "    if isinstance(value, (int, float)):\n",
    "        return float(value)\n",
    "    if isinstance(value, str):\n",
    "        return float(value.strip())\n",
    "    raise ValueError(f\"Expected numeric type for number, got: {type(value)}\")\n",
    "\n",
    "def normalize_category(value):\n",
    "    if isinstance(value, str):\n",
    "        return value.strip()\n",
    "    raise ValueError(f\"Expected string for category, got: {type(value)}\")\n",
    "\n",
    "def normalize_boolean(value):\n",
    "    if isinstance(value, bool):\n",
    "        return value\n",
    "    if isinstance(value, str):\n",
    "        val = value.strip().lower()\n",
    "        if val in {\"true\", \"1\", \"yes\"}:\n",
    "            return True\n",
    "        elif val in {\"false\", \"0\", \"no\"}:\n",
    "            return False\n",
    "        else:\n",
    "            raise ValueError(f\"Unrecognized string for boolean: {value!r}\")\n",
    "    if isinstance(value, (int, float)):\n",
    "        if value == 1:\n",
    "            return True\n",
    "        elif value == 0:\n",
    "            return False\n",
    "        else:\n",
    "            raise ValueError(f\"Numeric value not valid for boolean: {value}\")\n",
    "    raise ValueError(f\"Expected bool, int, float, or string for boolean, got: {type(value)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pAwQecYJYp1L"
   },
   "outputs": [],
   "source": [
    "def normalize_list_category(answer):\n",
    "    \"\"\"\n",
    "    Normalize an answer of type list[category] into a set of cleaned strings.\n",
    "    Handles both true lists and stringified list representations,\n",
    "    and removes stray square brackets from individual elements.\n",
    "    \"\"\"\n",
    "    def clean_item(x):\n",
    "        x = str(x).strip()\n",
    "        if x.startswith(\"[\"):\n",
    "            x = x[1:]\n",
    "        if x.endswith(\"]\"):\n",
    "            x = x[:-1]\n",
    "        return x.strip()\n",
    "    if isinstance(answer, str):\n",
    "        try:\n",
    "            parsed = ast.literal_eval(answer)\n",
    "            if isinstance(parsed, list):\n",
    "                answer = parsed\n",
    "            else:\n",
    "                answer = [item.strip() for item in answer.split(\",\") if item.strip()]\n",
    "        except:\n",
    "            answer = [item.strip() for item in answer.split(\",\") if item.strip()]\n",
    "    if isinstance(answer, list):\n",
    "        return set(clean_item(x) for x in answer)\n",
    "    return set()  # fallback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ppBBUbJIZAAt"
   },
   "outputs": [],
   "source": [
    "def normalize_list_number(value):\n",
    "    \"\"\"\n",
    "    Normalizes a predicted or gold value for list[number] questions.\n",
    "\n",
    "    Expected input:\n",
    "    - a string representing a list of numbers, e.g., \"[2, 2, 2]\"\n",
    "    - OR a Python list of numbers\n",
    "    - OR a stringified CSV like \"2, 2, 2\"\n",
    "\n",
    "    Returns:\n",
    "    - A set of floats\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if isinstance(value, str):\n",
    "            try:\n",
    "                # Try parsing as JSON list\n",
    "                value = json.loads(value)\n",
    "            except json.JSONDecodeError:\n",
    "                try:\n",
    "                    value = ast.literal_eval(value)\n",
    "                except:\n",
    "                    # fallback: comma-separated\n",
    "                    value = [item.strip() for item in value.split(\",\") if item.strip()]\n",
    "        return set(float(v) for v in value)\n",
    "    except Exception as e:\n",
    "        print(f\"normalize_list_number error: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h1-19ptFZRcX"
   },
   "outputs": [],
   "source": [
    "def normalize_answer(value, expected_type):\n",
    "    \"\"\"\n",
    "    Dispatches to the appropriate normalization function based on expected_type.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if expected_type == \"number\":\n",
    "            return normalize_number(value)\n",
    "        elif expected_type == \"category\":\n",
    "            return normalize_category(value)\n",
    "        elif expected_type == \"boolean\":\n",
    "            return normalize_boolean(value)\n",
    "        elif expected_type == \"list[category]\":\n",
    "            return normalize_list_category(value)\n",
    "        elif expected_type == \"list[number]\":\n",
    "            return normalize_list_number(value)\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported expected type: {expected_type}\")\n",
    "    except Exception as e:\n",
    "        print(f\"normalize_answer error for type '{expected_type}': {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B6dhw6KgaXZn"
   },
   "outputs": [],
   "source": [
    "def normalize_columns(value):\n",
    "    \"\"\"\n",
    "    Normalize a gold or predicted column list into a set of strings,\n",
    "    preserving casing and special characters.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if isinstance(value, str):\n",
    "            # Try parsing as a list\n",
    "            try:\n",
    "                parsed = ast.literal_eval(value)\n",
    "                if isinstance(parsed, list):\n",
    "                    value = parsed\n",
    "                else:\n",
    "                    # fallback: comma-split string\n",
    "                    value = [item.strip() for item in value.split(\",\") if item.strip()]\n",
    "            except:\n",
    "                value = [item.strip() for item in value.split(\",\") if item.strip()]\n",
    "\n",
    "        if isinstance(value, list):\n",
    "            return set(str(x).strip() for x in value)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"normalize_columns error: {e}\")\n",
    "\n",
    "    return set()  # fallback\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fqmGln_nwdjs"
   },
   "source": [
    "## Process the Raw LLM Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fVzbwtVawCN1"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import ast\n",
    "\n",
    "def process_response(generated_text, question, expected_type, error_set):\n",
    "    \"\"\"\n",
    "    Processes the raw LLM response to extract and normalize the answer and columns.\n",
    "\n",
    "    Args:\n",
    "        generated_text (str): Raw text output from the LLM.\n",
    "        question (str): The question (used for debugging).\n",
    "        expected_type (str): The expected type of the answer (e.g., boolean, number).\n",
    "        error_set (set): A set to store questions that had format errors.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[bool, Any, List[str]]:\n",
    "            - is_error (bool): True if formatting/parsing failed.\n",
    "            - norm_answer: normalized answer or None on failure.\n",
    "            - norm_columns: normalized list of columns or [] on failure.\n",
    "    \"\"\"\n",
    "    is_error = False\n",
    "    norm_answer = None\n",
    "    norm_columns = []\n",
    "\n",
    "    try:\n",
    "        # Step 1: Trim response\n",
    "        generated_text = generated_text.strip()\n",
    "\n",
    "        # Step 2: Try to isolate a dictionary from the output\n",
    "        start = generated_text.find('{')\n",
    "        end = generated_text.rfind('}') + 1\n",
    "        if start == -1 or end == -1:\n",
    "            raise ValueError(\"Could not find a JSON-like object\")\n",
    "\n",
    "        json_str = generated_text[start:end]\n",
    "\n",
    "        # Fix lowercase true/false if needed\n",
    "        json_str_fixed = json_str.replace(\"true\", \"True\").replace(\"false\", \"False\")\n",
    "\n",
    "        # Step 3: Try parsing as JSON first, fallback to ast.literal_eval\n",
    "        try:\n",
    "            response_json = json.loads(json_str)\n",
    "        except json.JSONDecodeError:\n",
    "            response_json = ast.literal_eval(json_str_fixed)\n",
    "\n",
    "        # Step 4: Ensure expected keys exist\n",
    "        if \"answer\" not in response_json or \"columns_used\" not in response_json:\n",
    "            raise KeyError(\"Missing 'answer' or 'columns_used' in response\")\n",
    "\n",
    "        raw_answer = response_json[\"answer\"]\n",
    "        raw_columns = response_json[\"columns_used\"]\n",
    "\n",
    "        # Step 5: Normalize both fields\n",
    "        norm_answer = normalize_answer(raw_answer, expected_type)\n",
    "        norm_columns = normalize_columns(raw_columns)\n",
    "\n",
    "    except Exception as e:\n",
    "        # On any failure, flag error and return safe defaults\n",
    "        print(f\"[process_response] Failed to parse response for question: {question}\")\n",
    "        print(f\"Error: {e}\")\n",
    "        is_error = True\n",
    "        error_set.add(question)\n",
    "        norm_answer = None\n",
    "        norm_columns = []\n",
    "\n",
    "    # Return tuple: (was error?, normalized answer, normalized columns)\n",
    "    return is_error, norm_answer, norm_columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TWLQob1p2YgV"
   },
   "outputs": [],
   "source": [
    "def safe_generate_response(prompt, retries=1, delay=3):\n",
    "    attempts = 0\n",
    "    while attempts <= retries:\n",
    "        try:\n",
    "            return generate_model_response(prompt)\n",
    "        except Exception as e:\n",
    "            print(f\"[Attempt {attempts+1}] Error: {repr(e)}\")\n",
    "            time.sleep(delay)\n",
    "            attempts += 1\n",
    "    print(\"Failed all attempts. Returning empty response.\")\n",
    "    return \"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MKgdW5Q0w292"
   },
   "source": [
    "## Evaluate Generated Response Over Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J1CnJMdUdReu"
   },
   "outputs": [],
   "source": [
    "def evaluate_dataset(dataset_rows, dataset_name, dev_dataset_map, request_delay=1.5):\n",
    "    pred_answers = []\n",
    "    gold_answers = []\n",
    "    pred_columns = []\n",
    "    gold_columns = []\n",
    "    question_types = []\n",
    "\n",
    "    type_wise_correct = defaultdict(int)\n",
    "    type_wise_total = defaultdict(int)\n",
    "    column_match_count = 0\n",
    "    error_set = set()\n",
    "    formatting_errors_by_type = defaultdict(int)\n",
    "\n",
    "    print(f\"# Questions in {dataset_name}: {len(dataset_rows)}\")\n",
    "\n",
    "    for i, row in enumerate(dataset_rows):\n",
    "        print(f\"\\n--- Query {i+1}/{len(dataset_rows)} ---\")\n",
    "\n",
    "        question = row[\"question\"]\n",
    "        dataset = row[\"dataset\"]\n",
    "        expected_type = row[\"type\"]\n",
    "\n",
    "        gold_answer = normalize_answer(row[\"sample_answer\"], expected_type)\n",
    "        gold_cols = normalize_columns(row[\"columns_used\"])\n",
    "\n",
    "        df = dev_dataset_map[dataset]\n",
    "        # Retrieve top-k relevant columns for this question\n",
    "        retrieved_cols = retrieve_columns_for_question(dataset, question, k=4)\n",
    "\n",
    "        reduced_df = df[retrieved_cols]\n",
    "\n",
    "        prompt = build_prompt(reduced_df, question)\n",
    "\n",
    "\n",
    "        response = safe_generate_response(prompt)\n",
    "        time.sleep(request_delay)\n",
    "        print(\"\\n--- Raw LLM Response ---\")\n",
    "        print(response)\n",
    "\n",
    "        is_error, pred_answer, pred_cols = process_response(response, question, expected_type, error_set)\n",
    "        if is_error:\n",
    "            formatting_errors_by_type[expected_type] += 1\n",
    "\n",
    "        print(f\"\\nQuestion: {question}\")\n",
    "        print(f\"Pred Answer: {pred_answer}, Gold Answer: {gold_answer}\")\n",
    "        print(f\"Pred Columns: {pred_cols}, Gold Columns: {gold_cols}\")\n",
    "\n",
    "        pred_answers.append(pred_answer)\n",
    "        gold_answers.append(gold_answer)\n",
    "        pred_columns.append(pred_cols)\n",
    "        gold_columns.append(gold_cols)\n",
    "        question_types.append(expected_type)\n",
    "        type_wise_total[expected_type] += 1\n",
    "\n",
    "        correct = False\n",
    "        try:\n",
    "            if expected_type == \"number\":\n",
    "                correct = abs(pred_answer - gold_answer) < 1e-3\n",
    "            else:\n",
    "                correct = pred_answer == gold_answer\n",
    "        except:\n",
    "            correct = False\n",
    "\n",
    "        if correct:\n",
    "            type_wise_correct[expected_type] += 1\n",
    "\n",
    "        if isinstance(pred_cols, (list, set)) and set(pred_cols) == set(gold_cols):\n",
    "            column_match_count += 1\n",
    "\n",
    "    print(\"\\n=== Answer Accuracy by Type ===\")\n",
    "    for qtype in type_wise_total:\n",
    "        total = type_wise_total[qtype]\n",
    "        correct = type_wise_correct[qtype]\n",
    "        acc = correct / total if total else 0\n",
    "        print(f\"{qtype:15}: {acc:.2%} ({correct}/{total})\")\n",
    "\n",
    "    total = len(dataset_rows)\n",
    "    col_acc = column_match_count / total if total else 0\n",
    "    print(f\"\\n=== Column Selection Accuracy ===\\n{col_acc:.2%} ({column_match_count}/{total})\")\n",
    "\n",
    "    eval_records = []\n",
    "    for i in range(len(dataset_rows)):\n",
    "        eval_records.append({\n",
    "            \"type\": question_types[i],\n",
    "            \"gold_answer\": gold_answers[i],\n",
    "            \"pred_answer\": pred_answers[i],\n",
    "            \"gold_columns\": gold_columns[i],\n",
    "            \"pred_columns\": pred_columns[i],\n",
    "        })\n",
    "\n",
    "    # Final column stats\n",
    "    wrong_cols = 0\n",
    "    right_cols = 0\n",
    "    format_errors = 0\n",
    "    for i, (pred, gold) in enumerate(zip(pred_columns, gold_columns)):\n",
    "        question = dataset_rows[i][\"question\"]\n",
    "\n",
    "        if question in error_set:\n",
    "            format_errors += 1\n",
    "            continue\n",
    "\n",
    "        if isinstance(pred, (list, set)):\n",
    "            if set(pred) == set(gold):\n",
    "                right_cols += 1\n",
    "            else:\n",
    "                wrong_cols += 1\n",
    "        else:\n",
    "            format_errors += 1  # fallback, shouldn't happen\n",
    "\n",
    "\n",
    "    column_stats = {\n",
    "        \"wrong_cols\": wrong_cols,\n",
    "        \"right_cols\": right_cols,\n",
    "        \"format_error\": format_errors,\n",
    "        \"total\": len(dataset_rows)\n",
    "    }\n",
    "\n",
    "    return eval_records, column_stats, formatting_errors_by_type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PpFIpuoyw9Cb"
   },
   "source": [
    "## Metrics Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7E-wLCo63zu_"
   },
   "outputs": [],
   "source": [
    "def compute_metrics(eval_records, model_name, model_results):\n",
    "    results = defaultdict(float)\n",
    "    total = len(eval_records)\n",
    "    correct_all = 0\n",
    "    typewise = defaultdict(lambda: [0, 0])\n",
    "    colwise = {'single': [0, 0], 'multi': [0, 0]}\n",
    "\n",
    "    for record in eval_records:\n",
    "        t = record['type'].strip().lower()\n",
    "        gold_answer = record['gold_answer']\n",
    "        pred_answer = record['pred_answer']\n",
    "        gold_cols = set(record['gold_columns'])\n",
    "        pred_cols = set(record['pred_columns'])\n",
    "\n",
    "        try:\n",
    "            if t == \"number\":\n",
    "                answer_match = abs(pred_answer - gold_answer) < 1e-3\n",
    "            else:\n",
    "                answer_match = pred_answer == gold_answer\n",
    "        except:\n",
    "            answer_match = False\n",
    "\n",
    "        col_match = gold_cols == pred_cols\n",
    "        joint_match = answer_match and col_match\n",
    "        if joint_match:\n",
    "            correct_all += 1\n",
    "\n",
    "        typewise[t][1] += 1\n",
    "        if joint_match:\n",
    "            typewise[t][0] += 1\n",
    "\n",
    "        col_count = len(gold_cols)\n",
    "        if col_count == 1:\n",
    "            colwise['single'][1] += 1\n",
    "            if joint_match:\n",
    "                colwise['single'][0] += 1\n",
    "        else:\n",
    "            colwise['multi'][1] += 1\n",
    "            if joint_match:\n",
    "                colwise['multi'][0] += 1\n",
    "\n",
    "    def get_acc(dic, key):\n",
    "        correct, total = dic[key]\n",
    "        return correct / total if total else 0\n",
    "\n",
    "    results['avg'] = correct_all / total if total else 0\n",
    "    results['boolean'] = get_acc(typewise, 'boolean')\n",
    "    results['number'] = get_acc(typewise, 'number')\n",
    "    results['category'] = get_acc(typewise, 'category')\n",
    "    results['list[category]'] = get_acc(typewise, 'list[category]')\n",
    "    results['list[number]'] = get_acc(typewise, 'list[number]')\n",
    "    results['single col'] = get_acc(colwise, 'single')\n",
    "    results['multiple cols'] = get_acc(colwise, 'multi')\n",
    "\n",
    "    model_results[model_name] = dict(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BZderNPKDhIo"
   },
   "outputs": [],
   "source": [
    "def format_percent_and_count(val, total):\n",
    "    percent = 100 * val / total if total else 0\n",
    "    return f\"{percent:.1f} ({val})\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1kHzthxkxW3P"
   },
   "source": [
    "## Trigger Pipeline (Iterates over each dataset one after another)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1746644586017,
     "user": {
      "displayName": "Prajakta Kini",
      "userId": "16853765155046300123"
     },
     "user_tz": 360
    },
    "id": "phWKLvxBIS0o",
    "outputId": "caf69c80-6ff3-413d-f950-fb7143e6e79a"
   },
   "outputs": [],
   "source": [
    "print(len(unique_train_datasets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2178942,
     "status": "ok",
     "timestamp": 1746646766372,
     "user": {
      "displayName": "Prajakta Kini",
      "userId": "16853765155046300123"
     },
     "user_tz": 360
    },
    "id": "qedDmG4Ezwu6",
    "outputId": "6a3136da-abe3-4e05-c916-edb8ec764d7c"
   },
   "outputs": [],
   "source": [
    "model_results = {}\n",
    "column_quality_table = []\n",
    "formatting_errors_summary = defaultdict(int)\n",
    "\n",
    "for dataset_id in unique_train_datasets:\n",
    "\n",
    "    dataset_rows = semeval_train.filter(lambda sample: sample[\"dataset\"] == dataset_id)\n",
    "    print(f\"\\n\\n### Evaluating {dataset_id} ###\")\n",
    "\n",
    "    records, col_stats, formatting_errors_by_type = evaluate_dataset(\n",
    "        dataset_rows, dataset_name=dataset_id, dev_dataset_map=train_dataset_map\n",
    "    )\n",
    "\n",
    "    compute_metrics(records, dataset_id, model_results)\n",
    "\n",
    "    column_quality_table.append({\n",
    "        \"model\": dataset_id,\n",
    "        \"wrong cols\": format_percent_and_count(col_stats[\"wrong_cols\"], col_stats[\"total\"]),\n",
    "        \"right cols\": format_percent_and_count(col_stats[\"right_cols\"], col_stats[\"total\"]),\n",
    "        \"format error\": format_percent_and_count(col_stats[\"format_error\"], col_stats[\"total\"]),\n",
    "    })\n",
    "\n",
    "    for qtype, count in formatting_errors_by_type.items():\n",
    "        formatting_errors_summary[qtype] += count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wmmTVQIUxhff"
   },
   "source": [
    "## Print Metrics Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 56,
     "status": "ok",
     "timestamp": 1746646780099,
     "user": {
      "displayName": "Prajakta Kini",
      "userId": "16853765155046300123"
     },
     "user_tz": 360
    },
    "id": "rJs_UwtyBRag",
    "outputId": "3a62ae4d-f9c3-4ff2-a10f-0d4198aeb128"
   },
   "outputs": [],
   "source": [
    "# Table 1: Main Metrics Table\n",
    "results_df = pd.DataFrame(model_results).T.round(3)\n",
    "print(\"### Main Metrics Table:\")\n",
    "print(results_df.to_markdown())\n",
    "\n",
    "# Table 2: Column Quality Table\n",
    "col_df = pd.DataFrame(column_quality_table)\n",
    "print(\"\\n### Column Quality Table:\")\n",
    "print(col_df.to_markdown(index=False))\n",
    "\n",
    "# Table 3: Formatting Errors by Type\n",
    "print(\"\\n### Formatting Errors by Question Type:\")\n",
    "for qtype, count in formatting_errors_summary.items():\n",
    "    print(f\"{qtype:15}: {count} formatting errors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Su6b6twUxm8-"
   },
   "source": [
    "## Compute weighted global averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "8f258a93bd78466ea8504fcddafbc0f7",
      "6050e93e8d9846409e3a4b8cba78f2df",
      "3bafa4062c6f4405ad8e5a439e70a7ca",
      "998957beb63c4fed8dd8e7e67811dcdb",
      "4f17ef721950458a88af9cd04b75f536",
      "c7084aab6984410ea1be9e61f44fd6b1",
      "020a089df561443191844387f914e0db",
      "4ae411f7f42f4c10a12c696e576ab845",
      "ed8f8750e16948f280e19519274598d6",
      "694b18d4d9ae4c259457453bd8600027",
      "24c313a9393d4e088fa91484d3f68009",
      "fa77bd262f2c47b091102f243ef2c0e9",
      "8326cfc7adac4224a357dc7f01bd0d60",
      "1831f7d733f8463aa8c7458bcb2f8e6a",
      "5266e675b4064533bbf654891fece939",
      "337c49de6dab4743bc3b0be24c132f16",
      "a2f1999dc3be4e17b08fa2f5877931f5",
      "543f4825b41a47b19218d502e60f27fb",
      "5ace169235da4b3a8ad5a94380a91549",
      "c66d1091a62e459297109bab0242a15e",
      "b9271a59502c416ebe32781f718c6398",
      "272dd1c33d664c2487a38d2a512c110a",
      "bef4160a94b94cb5884ed66afd735653",
      "badd522ac4114202954183138739d3f1",
      "523c0c99dfb14aa3b4d0185c33462a8f",
      "33cdfab891394d4a905731c21724f565",
      "7ac00b592a7f4b57b54afbb63567c997",
      "e5295a271d854c07a9b7775b650165d8",
      "3405951f91464dd68c1295ae1c4dbfad",
      "7205a1044ca94bd9a60ea702310372b7",
      "5613f15d29e640208471d61534db4a82",
      "5fd4b7523f5c452780d641570f11ef01",
      "fdaf8105f1a442b4ab47882482f83f97",
      "2b572b8c14e44e3b845a595c122a1f44",
      "5fd92cd463374d38a0b479796daaa23b",
      "0ebc09337b7f484089211d19ceb2c60f",
      "b97fd66aee1f49ca9149b28540104d65",
      "45b649932c014979bd4db7f004d4d5db",
      "fd37eed9550c45af9c0ecbf28a6bfa13",
      "6c5448d130fb4ff4bb1c4535735709ac",
      "1544fb88d0094d25af076be744b708e5",
      "5607beb5b9f14260a3fa4933365359b5",
      "47a1e5ece9884762bc0c4e11b904111f",
      "12dcacb952ee4c89a33361a64fd18400",
      "863bebdf3d4444ddbcfbd151e7db6a0e",
      "538b3a7246f44007907ed8e3fca7ab30",
      "8df0acbf3e46415492e7afc7d392c997",
      "79dba4cac9804e91bff9becf842ae3d3",
      "22642e2c17d34b29bed922b1a7383724",
      "d26ac8f5b05044479740528284889825",
      "69b637bcdc4d4cd28bee7c4043c2c965",
      "793d2b6308f5486b8761dac56e20bc58",
      "2d457adda1db4dba816b056d09646684",
      "29918a85b8d14487a60f24245c43d052",
      "2650f80babc9401caea6cdf2aba57462",
      "ba71f1429e9043aca14d44ce3764d617",
      "73cbaa43787e42a2986cc0ce924d13ec",
      "1264463055b14c47bbf8b68e08248d70",
      "5933420664f64b3298aad5ead44e56d0",
      "16a8349bfb29423fb6e5990d98b14504",
      "db59f4df54b04d2693d806800a348978",
      "30bec7d9b51b49e69cee941910f0da53",
      "ce521ae607724e0e8fa4c7dd9c690a96",
      "986cbbe4f5474920849d47dbcadd3008",
      "0a322f7dd53b4cf2a0b08e7e3b9a7f65",
      "88f6aa208dc545339855bca1ea01a535",
      "f9eec18022c9460b86edf641e338bffc",
      "3d15100c3d8745ab868c4de8896ab01d",
      "c783e75450dc4f25a28cb57dda7e1548",
      "6695327fa30848d3986bab3b23a570d7",
      "0a67978cab724071b64ba697f284d953",
      "0262a0d6b6c74235a7b270d7d0bffa51",
      "87ff3e26b2f443bb8f7ad68b5af23bf4",
      "d25510269e284a20b63a1acc1a4518b7",
      "5e6f06324e574f1e91358308c7577374",
      "cb3b13302a1940f1a464f439e276a719",
      "c21f49d80108498cbcb7cf0173841fe1",
      "7850c560e9e74657b732daa5afa9b4fe",
      "d52b5d63cd9b4779bfaffaf996aa369c",
      "b89a3c26171c41399f37a12bc45f832a",
      "d337faeea11e4066b3dbe68da4e1a715",
      "2d427035ad47457e9be46c49571b6f48",
      "467fb21c904b4860ab5428ad9151fc3c",
      "afcebe892a33443b9a00787d9f17c2ea",
      "8c0114a096ef4d1e9a8393ce9e52addf",
      "cba6a125e3774441bb993f9dff330e74",
      "9d0f7bd80ce642bab43933358dc5cf4b",
      "bdcd15a0d02745728b0f311298bd7a57",
      "cf607e29ba7544c2bc5a213a25f68851",
      "bb7152a444d74697bd842e67b850855a",
      "bf5c1d46a638466faed3f7f24b2385db",
      "181e4c21b1a14e24b34f9ba49b4ed1ec",
      "067f13b5fb974154859c91b2f90822bc",
      "0996e5b4c0e2468b8acbab360bf55cc7",
      "6e8287231a774ae8958a6d665c2e34bb",
      "508b8697c96e437b8b7441f45f1cb9cc",
      "381eb91c738e4843ac6e343eb691202f",
      "36548e46fdc24ca6984f531d80034af5",
      "3b6b085807a04846ba3cf72cb9cad67a",
      "248a12dd536d4214add92377fb205100",
      "9d1b9b6504ed46ebb7b4d54091decc95",
      "3a7e2c7eec884578966da4f5834b30d8",
      "69f37ee996564bc9b6af4069e0db32f6",
      "d01b12d344564941ad174ad4828367e7",
      "591534d4efd949839bc4131cd338c140",
      "28d42991fa2540809d54fad428d5eb4a",
      "96ed17c9eeb74fca8333e8509503ea5a",
      "785f41185aa94e0a9e272571495261ed",
      "08586bddeb8f43d88d6aeb5b783d9c8e",
      "1d28da742d814dfa88e4100b873336cd",
      "ca9a3d2367e34e5cb40cde2360884fda",
      "e8560fd604384471a9261958f5981679",
      "656f4d422c764ab8abd08efe22fc23ba",
      "818d616a47d044bfaff3f462de1bb28a",
      "cf6dead84bb24a77a29754b63ccf066f",
      "6a248a413e934f30a84cbbe5a5ee482f",
      "cdb5493a3c58473a942ba471469347cd",
      "837b0eb22264435088ce1fbe2b0c4825",
      "e363f19d86994c138705e975b625b6f2",
      "7e857a80f1804375aa49b7d78e222ede",
      "8636d88c9ba44ad7b14918db4a977fb4",
      "375e77b3a32d4902b71aaaa27ed09e10",
      "ad2bf6e9c3364b4292f71e45fcfd61e7",
      "c38047ab434d427a9154fa1444ecaeb7",
      "c05db0012c79477fae14a5233b56384c",
      "b82eeb67580b45f8909e19c449075b4b",
      "03b4b871c9f148a5b41bc12c786d77bd",
      "ff7d1a89dae94e27a31eadbf567896de",
      "73315447f4ef42e8a17432c782c6fe29",
      "e9028ef415a24814bcdd447df2da5e85",
      "3f33f06208f143628680822e9bff4898",
      "35f6461a9b0b45acb5f3ba2318da3dfb",
      "a1bd3446697e4da7ac1ca459a9e5ca13",
      "c8ee8d233eea45afac74b524ef00469d",
      "ce689fe4713f46b2a05f2d4e24fb83cf",
      "64a6e8a62ab541e5aabfb1a992b97f90",
      "cbf83661b15b42f4a06e07f4aac17fa1",
      "cc936c986b1e4a9ca089da9147f10233",
      "cdad5c06e1b14160bf59756c8b39dbda",
      "cdb723cd271541e4a05d20a125a54de2",
      "1bd67c4db1c746ec9bb5eff11610879a",
      "a327d001109e44f8bde3c1eb2410f5a4",
      "f8744b53725d4af3a4c19666eab383ed",
      "ad3caf8325534d4391b65424873384a7",
      "d7b157b458ff42bfb5ed10b9cabf882c",
      "ae2a976471644bec97963e36ed1d5bdb",
      "c0ec083ea6a34bd58184e288d8f8ed3b",
      "94e6bc595b13466cb3bc1b92cbde5fca",
      "96e618f8552b4f86940fe913aea47dbd",
      "ffda7bfcb06949efb29527b832452539",
      "231031f1c9ec4dcd82d330b7bd61d8eb",
      "5520790b64c04e80ba8f8ad824f77ba0",
      "13ad9941fc124faa851fd1411ec0b254",
      "c673e7a0497a4a1ebde6cccb1e276e76",
      "1e8cc8701c894d2483f949e90a609d06",
      "f6ed4da7537142708397f753d4eade31",
      "fc4b9184847a4243ba80e487a1be120a",
      "4ce403b262fe42eab74217b756126cd1",
      "73599c0172264e84b34d1cfd26f8bf1c",
      "5ef04fe86a9d4009afc4b7264bee40c1",
      "bb83e7f8bd1a4ae5a539ad116ea06c25",
      "3d0b142489bc46058af5b7f8edb81d1c",
      "49eaf4a1709842ef9461fd144bf1a9cb",
      "adbd3178c95347cd9f27fc6a0c283ca7",
      "ae1bcc0a951f48bea15a9bba0dea8b18",
      "eb3d5edcd3b74d9b8f9386fb45ffdb4f",
      "4a5e79ca691b4103a9a5ead2c4cce508",
      "6e099f5ad0b24dc9a2da2383dce77c30",
      "68198ff326a9495e8ae03b9cba0cd15d",
      "cd6b86b453514e65aef2c2b82173be43",
      "028f46a629204a26b2a50b23d5c5f039",
      "c082df9d7a4948ab92e67a73c637b5aa",
      "822869e603544537b660b401c282482e",
      "bcc37321f62d4c27b5bec396839228a5",
      "1f1c6dc68c6f43cabff24f35fbf7382f",
      "55e2e30d0c07456ebfcce70146017a92",
      "a9ce6aeb88574150b1db21f3d488809b",
      "fc14817fe4d44cf7b493c889d7ac634c",
      "6d9e3c179b3a409d9d82a4d09c450643",
      "cb7fd7b752894e95b7813deffee9dd5f",
      "2ca93b278484490e96e73c61cb92af2d",
      "fb6dbf9ea92042738d55f95b77a22e2b",
      "68bfff696fce4de4881d184d97455fbf",
      "3d69a743f285424998ec95157f4e0064",
      "d465bcc37c3343608a895d50b466363d",
      "b6ab4b8d6c2b44d4810a22f496aa4780",
      "5d8cffe6411c445ebec1bf51579ed2fc",
      "2643e7afec6242de95b67d02094e442b",
      "70157af2a14a4935b398d4433360cf19",
      "8afd6e09903c4424af66c9bef711708b",
      "b2c6582e763c49fda4bd0396972e301d",
      "e7c19c3e318e4f8f9ed5d774b2c3a16a",
      "ca233c7792c04c198df0f5dfec5bfd7e",
      "6d1029905fbf46428914ebd667906250",
      "69b28c6cf07b4bb9ab6016460eded8ce",
      "27deda5a0c354901b1c89a42ffe72a16",
      "0eae39d2db094a23b69f36f6dd6ebede",
      "de4822d8beb644088eb64cea74206e0c",
      "4ba594d5677b40d7b10a7b4876b444a2",
      "5d71ecd0621445158290c7715c690665",
      "a01c6422209149f4b0853c688dd20721",
      "2be13555d1d64531888d08c2c2e8384e",
      "3eca49d8e6d642d2b9b63aeae5c96b4b",
      "a9694ef45a144956863d3c1038b6b61e",
      "ca6f72c20052472ba9c684913da41994",
      "f535b5f240714ecbbb5411dd1e69f2b9",
      "859aa2eb20c3476a8396b458c824c02d",
      "1149931c2cfe46a4871e0209a340dea6",
      "bb18891962974c48af51994e684ae011",
      "5601e5e73f754cafa08d981f82d877c6",
      "43d2f2d6da9145d7a827b29fe0159974",
      "7c0f3455613e44e3a379d2f23e1df933",
      "a35709564a324abfac89cdc8ad9f6361",
      "d68fe845f110497a9dc860956665f8d8",
      "0b8e8d2a1a7c4a17be1b635756dfb208",
      "492f3e70f1594aa1af75c6d9095bdd81",
      "a24d76e5677f44708a71be4cf07e8cde",
      "3f0f7cf5fea648e0840ec2ab1ec40827",
      "01ed71c5d9c04927b29be959000bc5c7",
      "d9d34c591cc04229a0863c1967d250df",
      "72f42e8b6b8a4e3cba2e4b5e10f078cb",
      "7577f47167d94f26bb8e7f59a61b7eaf",
      "2910f617ecb643bb9eafc36629008c46",
      "9aa636596cbe42e299473f91729bced4",
      "da094fdfcb0c41ce83e3a6ce4945a845",
      "cdc4d9980fce456684241737bda0016b",
      "b43ea4fa8e3041b8b8db8b05d4ac398d",
      "9e8bda752cf0429f8360b95a6f6348af",
      "2e63b3c66d794c68abdaf38c3d359109",
      "0b519e3ea4ad42878c1e8347df4477b0",
      "0d5fc8cd99df40728d114455e1704d15",
      "7a65b129a85c4f128b6caf702e994c5a",
      "e0df6e44d0094254b366421ec59a5232",
      "de3327ebc9fd41fd957a0f4f77f691e8",
      "7fc312481c5e4336a4a27f38eba979ad",
      "51bf1a0cbcb74c73832a21acde57bd50",
      "8a19875a1aea4d43899596598ec2253a",
      "5a6c3ce2f0ac470dabe1f213733adb70",
      "61e19a3d7eb6427da5526e68d4d6aebc",
      "2096a728792143eda8ced79d61a284b4",
      "e21fb35edcc1468fa7681e2482cb14ec",
      "3fd59c517b164cf58a7bbf8ee1c7be86",
      "db6f3648abcf4cdb9ff9a11c3a732e8d",
      "dee7f585e6df438db455eb7e7ec45986",
      "caea52c016f7490ba0183c7c48b32d67",
      "ddec755f3a72416a8cd02f14c2eafb19",
      "79ea21936aeb436b9ae18f144f39a61f",
      "f86a33c7ffbd4d359d1100bd6f770f35",
      "ac9b0cff9ce84aadabd9e8be16287f76",
      "3afe847e430f411aa53624c31f9e7c40",
      "ac7df89bf2284ea08f325ceaf0eb686e",
      "1566a88428234453abed02c85adbe516",
      "b63abdeb167c4b729b7acb190cb749d3",
      "f0a25f3a23eb47cba240d00344555152",
      "90367816074b409bbcab5bf356796834",
      "bd8aa0c669c1419487fb6d6745fab2f5",
      "9a9751424cdd4375bf8401e9dd0bf23a",
      "a9097f3870944af284c1d185984be852",
      "b5786ac3038742768519f09e0f5b7c12",
      "f89b7c80753e4b8da8f1cbf8dfbb57e6",
      "030ba768082044078d8e42a193b94e52",
      "b037d1535b8d44a5a262974a2f0406bf",
      "71c9a90eb7cd4369a33b20aa6b9e46cf",
      "c7bda4e9b868476a85beddb1ed2265b2",
      "00313d0243644e1382ddfd1060027935",
      "e7a67509da174cccb14abcf89bb20e8f",
      "4cd3704e82ef46d785a69d7c31b55bed",
      "96599176c68f4295ad3ce652c7ec6ba6",
      "9e3d79e5b3444249a19736937682b848",
      "8a2af93a75ee4a42abc5636a565826a8",
      "725d2906e06740c59fdcd45647661af1",
      "54b058d854c74bd490daa79f8ea30dcd",
      "1f982aab61c443d7bcc33a5d3ba1ad74",
      "94afd2e01c624bf6aace308c9c352102",
      "d4f1897485ae407bb4d02ccd9ae13395",
      "22510d85bec84d9e9ac087b63c50e329",
      "696919d34952449987347b95ea22f225",
      "0d0800b8a1fb465bae1c6d4cb8033a41",
      "c2d55f38169c4170814c878d5359c74e",
      "dfa7a40144c94ba0a877fb70c931f69f",
      "535a447a637c4813b23a74ab46ae66ec",
      "8a7d00005b5449bdab390cab22677057",
      "a4319ec9817846b1b195dac10b0967e9",
      "6f4ba9b3f05a4dff8d0eebd64f599a3d",
      "dffd9f63137a48bc8b94cedf17a2d547",
      "066bd0444ae24d99b3183a6193fb92b0",
      "a81591b1c4fb4d0da77e3c483d1d5294",
      "6acaabfb5c954db0b289b0525da6a4a6",
      "d458b91bab424a6aae3124ca05a7aabb",
      "ea427b92bba04117a3b83512051fe76a",
      "4a499e68a941449493f893084af68619",
      "a805c01fd27c4777af79a41f22207d79",
      "4411252b78a54cc6af7495867ae3dd03",
      "184c06435c6d44bba45fa270e5d60b96",
      "aaaeb9fd373c4fab93b37482f1b719e2",
      "16ebdcd683314fd28a4d1d45797f5e29",
      "24fa3c9883364a70b60fbd6fa847e4bc",
      "1596c530eb3347c980c684464d2db524",
      "b7fc1f785da749a8b8b0179deec6fe75",
      "8f93f574c90947ce8210b2ed5cef367d",
      "db7578a03f3f40b69376aacaabdaf9b2",
      "3a5d4a44ed274d33adef440e53279049",
      "24b91af21ebc4fc0b21d9d0dd0a8d9c7",
      "8597f507036a4e1a9035465f49e4bd09",
      "3c09eb3e8fc142fea1e4bdbd5e42fb63",
      "bb3b98a6cff948bda053cf75e837ea9f",
      "f6a07ae3b0054567b76fb804e16f7359",
      "472e9c6862b4481db02582da4e8eb53c",
      "df5cd2a1d9ce4f52a709d8624010138b",
      "bb5e54f076cd424798da75ed38f6f2a1",
      "94cee4904385478b9ba28bb716bc585d",
      "8abe996c48d441f6a22e88dac6bb5b2c",
      "47e00e5f8c5343b0a421a1a3d495c795",
      "3d81418a07fc4417b0e71835db3a7bbc",
      "62f003bdcdca4c37924cef786e2d5817",
      "ea6e54ac0e8e4a148c6e6d7575f4d473",
      "ef255d2c4bfe4cb9a7e6d73c3727cdb1",
      "8d9da5c439f24e9c8b4c8532780b53ac",
      "b0e99c5879444f28bac129a552d45066",
      "f91feb284b7f4c88bd9137de8f33c6e5",
      "0128335c465547268e15c69e7f06018f",
      "7fa472b8754b491cba14c03b3efdf57f",
      "8288c972d10c4ee3bf11cf883443ef04",
      "46f21c70c2094b30a3faeefbd06becc6",
      "ca263f5387a347f696ae989f73ab40dc",
      "0cc7c53cc5d5452db2a7e385e5f1ff70",
      "bcae8b025492493bbb63c315fbad14f6",
      "3563b567091c419f84ff2b337f64f02d",
      "e686028e563746a4b29c045f01aa57d0",
      "2fc661490210488f92ac13989b6f961a",
      "2a4b0fc0129a4fa5ab2653a8f6c06ad5",
      "84391f8ac10c4167bc3be1486c677940",
      "568f50ec97634f3ca9aa75a4afeae2e9",
      "e8df9691b0e042e79c1af0e69732a0b7",
      "a901c78be029408193bc388bf0439eb9",
      "41c224e349b34773b286433336711198",
      "9bce5b1a3f054cf8b56affd9413d37b3",
      "936b8d9cab88412aace34cdfdeb0c09a",
      "4ccc5045ee7941b2a1627ea3f2246a90",
      "7b9234e205774944bfb97400722101c6",
      "8c18cc935bf04d849c20573e9a493a17",
      "1d45626f3f83415399d31125a35f8348",
      "5f8ba9e2c33143c0a5aa3d6767f608ff",
      "98483b868bbc41b8a3bee5f0c695aaed",
      "0fee60dd8b8843258b6cf994096901a2",
      "55449823d18e4cc9b3e11f20782d2874",
      "b12590e868d249a6a19db3c2967095d2",
      "bddc8064f30241789f2efeb621ef8421",
      "b651cdec93564c1ab2ad0e80191ee5e4",
      "14552542c4ec470195dfda9be5441d5d",
      "a5bdea66184b485e92d2a62513f806cd",
      "9ddb820b4edc4d4d8b41c01194734315",
      "754872ba051345e7ad1a1326924f1508",
      "396c7077d4bf4ebda1fac4b1eb8eac2b",
      "f9938ae6b3f940df9feb28949148e15c",
      "4c4eda4a4a6444a3be54626f3a597040",
      "8f7b172db7d54254aea56744903c04e6",
      "ec620ae669864fdeb19698a3f15023e7",
      "72895ed4bb5c493abca7903f29af2fb5",
      "730bf4b5d0814947b05e9ec596be9759",
      "e967a50e780148cd81151203ad147d65",
      "39c2db0b7a45414eb10aaf9eac346cb0",
      "89585ff7d33d4203be722d627b94d53b",
      "0de83e868b1348928ea9794e41ba4713",
      "c384d8ec6d30438c939b3e3b798a8b32",
      "9af19ed1c2624d7c91684ff6d15f0ddd",
      "d43e045663634f23a0bed67a448889a4",
      "a8831de01d8c4c14957762e056293adb",
      "d6e4fd3a65584c30b60d3d928626a439",
      "d50ce4e8e72445bd928e90d8ddc564f0",
      "bf4fa39171184a02911047f836fe5624",
      "af6b35a7655a451b8bbedbd7c98037a5",
      "765baf20317c4e918376eb2e59f7d1bf",
      "a81b2b68991e4b8fa413dfc246fde4f7",
      "ed8855f234234544bc463b85466c44c1",
      "011828eeabeb4d479f83eefadf3832f7",
      "8a7eb4392d8a4b83b58ce138b7ba8737",
      "c42cb9b679714c50a241a982f7451133",
      "2fc31b8fb78b4c0190380e2cd017b6c9",
      "83441eb568194c598cdea1ebdca4490a",
      "de6d0a228145401398d754869a7369b0",
      "52e78e59f92d41948d0e77bc8e22278b",
      "2227c6b5651645e5983a9342a9d41aa9",
      "d41c34cb13854a968bdcb830c61b2e6c",
      "3bfd5f729f574c4f88c61f1a57bde8b0",
      "c9846442a0334351b83a89fd3fa9d94c",
      "85c4bce81a7245a19f92a49e91deba47",
      "80ea3e6749da409bab7d68f8d1f957cd",
      "5e241e30aec5426eb9b1a267e2ac3640",
      "a4ef7e7944c34c96aecc0a270590a500",
      "4587cdcfe01d4d1faafe758fd5184577",
      "4dc3f1677426447b8bc040c244470d32",
      "3ea4e8ba84e242b0bab9979f9aa6cf84",
      "9de31df6888b4405a18091d001ffb130",
      "46641794fb10471abafe206652d20220",
      "d5d46c8ff32e46ad97d6c1a6e3d1216b",
      "b18260e2c7254d59aa02eb4617948290",
      "dd9084a3e6a4443ea91a17678c44673d",
      "49b5e1bc0708400ea60bc00637121bd3",
      "4636f82c8e774b0abf7fbb48f3cb916a",
      "79940435a6f94a0ebbe57fb791067c4c",
      "dd2441e48ae147c0bd85da31c0e46481",
      "59224e70c11d4b14b6aa728600e566ed",
      "6d693a878c714bf782ff0654c8d3cf3c",
      "e7f39d95429346f089a01ea0ee8531bf",
      "e985909c50a349cea5093329edd62c85",
      "80fd6f09efc84fbea623285ca170c5d8",
      "ed2e0ee55c5041e5bde97617d6d3ef8c",
      "f580a61f3be74b0aa98919cc686c90c9",
      "84876695589d49b797c0d7beaca83cc2",
      "f0eb8ff3a7fb47de9d972f6f80c9d763",
      "7d0423bcd8034dd0b8f81f51f16f6584",
      "683d464e07de422d8b3878d78aade476",
      "26aefa0392d34900b8866cd2cda4331f",
      "1696efbdbf324a3597d112d630f122e5",
      "a7929401539d4290a111f8717ead323d",
      "29ef3fb0cf4d4ea8b8bcc4743172515b",
      "315a9c62040f416eb7369426f2c05ba8",
      "e35afcb2984d4e2797f35571c1bd49b2",
      "41785f4a5fb045f98d17c4d8153f6a03",
      "38f0f6de40f94750aed6d2d0e672597a",
      "b7e7a8dc24b54dc3895359c4cd8a0bb1",
      "7ae5041e9b804e578a0e68aff938f137",
      "a72c9965dbfe4779bd3ede3681525b23",
      "cc12f40ab1004ebea9933dd793d32ac3",
      "48d995159e7741968c71a3f1b38d487c",
      "d573bcebb3fd46318ad6dc2163f6f506",
      "2ebc808c05604888a2091d25ae26b584",
      "b4d17904b11445148382f12d7df7a7d4",
      "2ed4e473062644f39d1db8ffa3e6f526",
      "d1b019ce25224ba09f821c9a5a771583",
      "8d971a4e248d4467a3099e230f3a7e5f",
      "3d7beecbced64a8d874cd097a181707f",
      "7bfb3eb022dc439e94eefeeff4838114",
      "3364d060fbd44c31a7e0a9a62905585f",
      "35cd9c2b0393418b96b87f3ed750fcea",
      "1037c8f65c4344baa5b700f21a9691f5",
      "73665ab079e841a489ffb4009990ba9d",
      "96fd75e37fc54757b2cef7e3ae33dbc0",
      "8f1174f2d4af45dfbea92f2238bf05ab",
      "be736e4695604779b45d35481a371b2f",
      "ec2341afff944772bcf6b5db446ddad8",
      "d03d2ff537a64254900f77d2827ee249",
      "a02222e0b55c4533ab4d51bba27bb89d",
      "979816e4f1f941eea0beaaf2323e3aff",
      "d307344e3e0444348d97dc3974322468",
      "4e06c6fe7c844452ac9c2c12c69074d5",
      "9e175e4ad8a0455ab4436906ff416ccf",
      "8003112d09d94acbb8a6f35378d5925b",
      "6ce76de2bb224394b4910bbbfeefe822",
      "c90c55fdc5434403a5cfcf1431dd8cba",
      "33ef85183c0546708f0ba1a84b0567fb",
      "402670d92acf48bea57b04c97693231f",
      "eb84fd4361c14f6d98488fd40dc2e24f",
      "7f36061bf1144ce6aa1de4eb57816183",
      "27c2a5ea042f434a8053f2c72fea98f8",
      "5e07a03b2332411a9e5f444cc4fc78ab",
      "ccde265565d745da92d65f1b0ed98f30",
      "47958295e2d84054b44e4a6e0f77de63",
      "61253c393b184acb8e8ac935f85eb8ee",
      "8d0ed257bd9d46109fc8b9f1678a9a24",
      "18d64613732d41e39721aa3e58182f29",
      "9b728f40cc1a418da29c69a72862e05d",
      "738e246d06014d88bba12dd4797db095",
      "e30ed01bcb23457a8d0d9845fd2b638a",
      "784f9929ba1840098ff8a76a14e4fc09",
      "038f958a54a64e2d9870df75dbb9d807",
      "93d752ba36be4e46bc10041532e3ac32",
      "d35c63d32cdf4cdebec87f219c833d7b",
      "8d1478c739ca47b59197bfa666daf422",
      "b7a5fa0f8349411d8cb8c24a4a9c8b1f",
      "fb44b0eb2d444478be3c736a0d7b4c79",
      "b242d0c0312b405aaec9f7a519de22bf",
      "e3be5e839883451ca0417d91a973cab3",
      "0eb6b0753e354bacae4914eefd280c91",
      "d45a943bae72485ab878bb09f5be0558",
      "fdb633a71314476cb8be2d8746eb9c9f",
      "c364ccd6e07647fbab446eb379a189d4",
      "85bbb3405910472998acdf4445988da6",
      "598f3af93562462395d95d03cde081c8",
      "ac7b71693c9d40c4a4e8ebebbf47b4ad",
      "e0a30b77d0d74652afa63ea5f64c8010",
      "12a2c5d4b13143a29e6d0ddaa1e7d8f1",
      "c295247ee5da45d088fcb9a6d9746509",
      "912cbc457681444580deb950709fa033",
      "17bf22208c674ee88a1cdee51cc99918",
      "82bcfe447b6846debf92636d3afc3f6f",
      "54a082169372451aaa7d57f052f64c56",
      "b4cbfa9c3d404fb080ac45eb8474520a",
      "0a5151436f174cf19e9a4b8d4cfe48b0",
      "167f85fd0804475b80c365281722bf99",
      "17765995a8844ee99356bb3277314f2e",
      "b91d34d547da4efe808e215a9989be23",
      "a7ce82db4d4a4a7f9bdfb177ebcd35ba",
      "97c975659da847f0bf72dc5bd69db275",
      "8c000a717d2342b08638f448700c927b",
      "de298b90ac384ec2ba94a61c43500b97",
      "31b93b0455f94e8593bbb10cd10c6cec",
      "329f19e591e84cd7a12fb07e7e21330a",
      "97b7a26047164364ba7118b4dd1a9a69",
      "9f3339f455e14c25a545fa1721a23cd7",
      "722e09474a84462caf3774689817676d",
      "b6226622a96a4feb9abe444f707700f5",
      "2748feee85aa480a860f78c6fb69a301",
      "d4fc8f7121be4cb1acd650c912569eb2",
      "c6aabf044c9540ba96c7f3c7a5f998f5",
      "79a6cb40fbbf4de68bd20035ad316497",
      "dd5623f55bee40f59130a8b0eedff450",
      "9f738a2bb22d412ea2213269f2460972",
      "c1fdf45a32a34adc9ab69c8e1f80b91b",
      "b7dde9d94d9743a8b2f4ba088d51a2f6",
      "044b04b19ea24f44a1babbce2a6aa5c6",
      "6d7eff48abf149aca65388146dc5c853",
      "cf701722434545e28f2e0a3dbd22d9e3",
      "2753b716c08544ec919f5463bb258f56",
      "6e57019eba2b415691a59345f8e304e1",
      "07ddafb9625549b4873a49e8e550ce53",
      "3e5716794b1c4086896d4e8425366edf",
      "29f2455eff724d62be621b8d58c7e54d",
      "83a444c4b8d44f09af58043e5fbc858b",
      "e9009141a98e4e9e8ce4f1e318a3a2c1",
      "4687e1c41e36419aae474b9f32ee0e87",
      "dc2ccc95193e4be2b8faff3cea3b6ca4",
      "c532f2c13c6c4bd282cb42995c37538c",
      "cb1fea8715364d7b87a55e6a6018b5f4",
      "111031b4ec7f456f8c7b9f3e7ed522ea",
      "dd9ce4d05fd44657913d9d627c8caa61",
      "6f6e6a04371d41c28fa378f83a2e7566",
      "4c255a4011d84973a286e31c13ced026",
      "5a677755cf9d492385e4ca0a1f11b7ef",
      "092ae27b94204d0488d02a48046dc590",
      "4f550df51f7f4fe9a06facbd0b9582ee",
      "aed3c781734341c78c85e3c6f36b52c4",
      "781b89339a3742508c58133c8302c4ce",
      "716ac01dc74d4cecac563df380134182",
      "fdd175f0cf0e48a3bbace03e8a82eb5f",
      "6fad10be63004b94b6e84789afe486ed",
      "096d6953cfe440388315263a991b013d",
      "80544bf3dee4482ca908fced10099cb0",
      "f0d9774dc70548bf8887e2aa6eafc30d",
      "f363573ec00f497693094d0761d9b4dc",
      "6287ad2d94ad44bfbcfc9a83694f2c33",
      "fa17cefb318b4aa5b2422747d7c6b407",
      "5767b8a2495640a19434a3c8295c0923",
      "d35daffb159b4381964d3e55c49f65de",
      "425e5dd473c74cef9aeb9d44644e4e10",
      "bef17a26f2164a5eac2c9ba39f1160f8",
      "a6ffc03f10804305bd4a7379dedd29c2",
      "835e8a6c5b9e46afa16daf0f65818010",
      "4e22f458986c4e128ae2ee764712995e",
      "08d2f602eae848fbabb5ed66fe976abe",
      "a7f129281a954171b15bdf717383cc56",
      "1109f8efc1f341d0a609b054234fe844",
      "d7973666e9144b518848c12ee57376ab",
      "ffbe63805b034acda01a4857f1af8d0b",
      "28c3af8e6d22478ea6908a2d12cd2cc9",
      "73e4ee00cd0145108e8467d8cd6bf01f",
      "0c94f1c8ca434816901b32e72c8d21eb",
      "0cc4c702495642fca651ae07ddd42aa1",
      "d3cc689288d047d582558ca18ca1a283",
      "2f3787dc65e54fea941a4830492c92af",
      "9a18a8c63aea4b878f2105f7ae727f3f",
      "0fc453ea3e4a4b2f900dca34fed04b1f",
      "883e258f05ba46deac2ac4d9a6739ca0",
      "75f17be360dc44daa29d6cc031602cf4",
      "9e5e1244334c47b5a0a3bd60d2872f67",
      "67925bb454d64875bca498f1b721d394",
      "067f0f03deee44d0abb50f427ff595c6",
      "df74c1d8a60f4c0e94373f17d37a1d7c",
      "4412c3756b28488bb0b2236d50be44bc",
      "10bd9db1400d44cf9746657369ce8afe",
      "336d4b5901c7492bba4e72a81f4f24da",
      "beed551b995740208d9b0c98cbe5b987",
      "5277b644b29747af8b54e6bfefabc903",
      "2469e6836a844f11ab7eff9f7bfd184d",
      "e223c12a9dcf49f0afdf825d8af82350",
      "8ae1f7006f524cda957cc9c2de8a83d8",
      "a4d360ca1b464a61bc1928d40c7a7f36",
      "3d5fa69e02154ee398f57785db631bf8",
      "f1d9ab3a7f074f75bb0f971d3907da35",
      "6800c6d166664ce6b25adea17dcd55cc",
      "448e4bf0e8684093aceb6bb64c2735e8",
      "6f09d768b9f641ce8be3eecdd91f3ead",
      "7af5dc738e8a42f386b51440c5d2d836",
      "4d04303a917045ada3db0d8a7c597e7f",
      "a6ff3766b18a4f8398653263e0d6cf78",
      "cf72ef48645f4b98818bd2b37c8bc24d",
      "3a6341b2387846c78ace71f041baef63",
      "11a7f1a0feb84902902a47f7cb465184",
      "1daf4c8ff983435d85d2ef34e987ee46",
      "1dd9d0e346b94fc2ba348dd0e4dbdd2f",
      "badc0b7ac5e94266b39aa1311d32dc4b",
      "33947248d6914a8395742ceffa46154a",
      "da0c98b69c274173b3d2afe89436d52f",
      "70d8c1a7efcc4c92a4d2b758bf74757f",
      "21b6054c585a4679adf5d2fa0306c3d3",
      "089800afe22347eebbdf7f4d0249775c",
      "b8e8937c8b3e407badfd5c1f1543f776",
      "80795d7404ac40a79886f5fc5c431c5d",
      "14fd487f9f7949468dab0ae44bf8ffea",
      "683ddbdf92a14b25a075f380c1f3c27d",
      "847e39e7b12f4a0e80f28b789b363650",
      "8d5c2e719f644e22a86d906534cbd1b3",
      "50b8c702b199451d842cbf5cacecf847",
      "ca887dda449c49fe8bdcb9c2ce3dc37f",
      "392bc2f9c0ce4e0083fa6dcfd2df978e",
      "106e4b96fb7b4065800a00db6b20917a",
      "76e7b0788bcd4fdb9e0500660df920a0",
      "61bc2fed61184a9991f59c5b9676767e",
      "485ba765c1d3483687214a3fcee49bcc",
      "65cf201d5b2e45da80a857265360f21d",
      "46c6a3f70bbe4d039394d3d65b6c4aa5",
      "39f034be50b542c9bf6565e464547d21",
      "8b2a65f1c16c4a2a86feee99394dac6a",
      "801a67fe42a24ee28aec9f938d44b8f5",
      "9e481eea8c1542a4b9417301c000a326",
      "688f5a03727146d4af37f391fee02bba",
      "f82f08e9b9fb48f7b1d8e4a204626d36",
      "c4a59cc93a894b66a3d91c7517d2777e",
      "a1cc87cf29144b2fbd0ac460d51192b3",
      "1193b2bf9aa54f76a3fa3eefd72a9c7d",
      "be2ea44c021949c39c1c838a1a39405f",
      "b05e8dac56134244ba005b09538c8256",
      "1334893327ed4aa1b55109a015193f99",
      "c3dad92499a3448faa1d38339c1c98c5",
      "f6059cc045674b3691e05b83e51eb6b3",
      "fba44776d0cb4f019988830f777cab0d",
      "97336e152e0141ff99b4fba8e033c0ab",
      "7b7f5ca54f16407a98a70f6f66c07b1a",
      "a383c6f06e414440982c5ef8adeecf72",
      "b45743688d3042a595371638e8838f1f",
      "f5e9199a2a55451f85c4af97637ecaea",
      "3f041d58d4444176bdee9507a269864c",
      "f412fad1abcc4d3aa65b94d5f0238f16",
      "33d206668c26438ab052afe02246e0cb",
      "e4f6a7602f994c749cb3c900ecff7abd",
      "f9a66b2b1927474986ac197d1598494e",
      "86282fbfe9634637a1faa1cd47f3947b"
     ]
    },
    "executionInfo": {
     "elapsed": 2955,
     "status": "ok",
     "timestamp": 1746646787952,
     "user": {
      "displayName": "Prajakta Kini",
      "userId": "16853765155046300123"
     },
     "user_tz": 360
    },
    "id": "pyNFH0w4lYeO",
    "outputId": "0def820a-c473-4dd2-eda0-3a888303a0f7"
   },
   "outputs": [],
   "source": [
    "# Store dataset sizes\n",
    "dataset_sizes = {dataset_id: len(semeval_train.filter(lambda s: s[\"dataset\"] == dataset_id)) for dataset_id in unique_train_datasets}\n",
    "\n",
    "def compute_weighted_global_metrics(model_results, dataset_sizes):\n",
    "    weighted_sums = defaultdict(float)\n",
    "    total_size = sum(dataset_sizes[ds] for ds in model_results if ds != \"GLOBAL\")\n",
    "\n",
    "    for dataset_id, metrics in model_results.items():\n",
    "        if dataset_id == \"GLOBAL\":\n",
    "            continue\n",
    "        weight = dataset_sizes[dataset_id]\n",
    "        for k, v in metrics.items():\n",
    "            weighted_sums[k] += v * weight\n",
    "\n",
    "    return {k: weighted_sums[k] / total_size for k in weighted_sums}\n",
    "\n",
    "# Compute and store weighted global average\n",
    "global_model_results = {}\n",
    "global_model_results[\"GLOBAL\"] = compute_weighted_global_metrics(model_results, dataset_sizes)\n",
    "\n",
    "# Display as markdown table\n",
    "global_df = pd.DataFrame(global_model_results).T.round(3)\n",
    "print(\"\\n### Global Metrics Across All Datasets (Weighted):\")\n",
    "print(global_df.to_markdown())"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
